





import pandas as pd








import pandas as pd
df = pd.read_csv("Crime_Data_from_2020_to_Present.csv")
df.head(10)


print(df.head(10))


df.iloc[:,:14].head()



df.iloc[:,14:].head()


df.iloc[:,14:].tail()


df.info()


df.describe()


# Exploración de primeros 50 valores únicos solo para variables categóricas
for col in df.select_dtypes(include='object').columns:
    print(f"--- {col} ---")
    print(df[col].dropna().unique()[:50])  # Primeros 50 valores únicos
    print("\n")




# Vamos a renombrar las columnas para hacerlas más comprensibles, se trata de un cambio en el Diccionario
rename_columns = {
    'DR_NO': 'id_report',
    'Date Rptd': 'date_report',
    'DATE OCC': 'date_ocurrance',
    'TIME OCC': 'time_ocurrance',
    'AREA': 'area_code',
    'AREA NAME': 'area_name',
    'Rpt Dist No': 'district',
    'Part 1-2': 'crime_severity',
    'Crm Cd': 'crime_code',
    'Crm Cd Desc': 'crime_desc',
    'Mocodes': 'crime_mo',
    'Vict Age': 'age_victim',
    'Vict Sex': 'sex_victim',
    'Vict Descent': 'descent_victim',
    'Premis Cd': 'loc_code',
    'Premis Desc': 'loc_desc',
    'Weapon Used Cd': 'weapon_code',
    'Weapon Desc': 'weapon_desc',
    'Status': 'case_status_code',
    'Status Desc': 'case_status_desc',
    'Crm Cd 1': 'crime_code_1',
    'Crm Cd 2': 'crime_code_2',
    'Crm Cd 3': 'crime_code_3',
    'Crm Cd 4': 'crime_code_4',
    'LOCATION': 'location',
    'Cross Street': 'cross_street',
    'LAT': 'latitude',
    'LON': 'longitude'
}

# Renombrar las columnas
df.rename(columns=rename_columns, inplace=True)

# Confirmar el cambio
df.head()



# Variables a explorar
columns_to_explore = [
    'area_code',
    'area_name',
    'district',
    'crime_severity',
    'crime_code',
    'crime_desc',
    'sex_victim',
    'descent_victim',
    'loc_code',
    'loc_desc',
    'weapon_code',
    'weapon_desc',
    'case_status_code',
    'case_status_desc'
]

# Mostrar TODOS los valores únicos para esas columnas
for col in columns_to_explore:
    if col in df.columns:
        print(f"--- {col} ---")
        print(sorted(df[col].dropna().unique()))
        print("\n")
    else:
        print(f"Column {col} not found in the dataframe.\n")















# Primero aseguramos que district sea string para extraer area_code
df['district'] = df['district'].astype(str)

# Sacamos el primer dígito como área (puedes usar 1 o 2 dígitos según precisión)
df['area_code'] = df['district'].str[0].astype(int)

# Mapeo de area_code a area_name
area_mapping = {
    1: '77th Street',
    2: 'Central',
    3: 'Devonshire',
    4: 'Foothill',
    5: 'Harbor',
    6: 'Hollenbeck',
    7: 'Hollywood',
    8: 'Mission',
    9: 'N Hollywood',
    10: 'Newton',
    11: 'Northeast',
    12: 'Olympic',
    13: 'Pacific',
    14: 'Rampart',
    15: 'Southeast',
    16: 'Southwest',
    17: 'Topanga',
    18: 'Van Nuys',
    19: 'West LA',
    20: 'West Valley',
    21: 'Wilshire'
}

# Asignamos nombre al área
df['area_name'] = df['area_code'].map(area_mapping)

# Verificamos si el mapeo está correcto
print(df[['district', 'area_code', 'area_name']].head())

# Contar registros por area_name
print(df['area_name'].value_counts())



import pandas as pd

# Definimos el listado completo de áreas (en el orden correcto)
area_names = [
    '77th Street', 'Central', 'Devonshire', 'Foothill', 'Harbor', 'Hollenbeck',
    'Hollywood', 'Mission', 'N Hollywood', 'Newton', 'Northeast', 'Olympic',
    'Pacific', 'Rampart', 'Southeast', 'Southwest', 'Topanga', 'Van Nuys',
    'West LA', 'West Valley', 'Wilshire'
]

# Hacemos el conteo de registros por area_name
area_counts = df['area_name'].value_counts()

# Aseguramos que todos los nombres estén incluidos (incluso los que faltan)
area_counts = area_counts.reindex(area_names, fill_value=0)

# Ahora, buscamos las áreas con 0 crímenes
areas_sin_crimen = area_counts[area_counts == 0]

# Mostrar áreas sin crímenes
print("Áreas donde no hubo crímenes registrados:")
print(areas_sin_crimen)


# Definimos las 21 áreas oficiales
area_names = [
    '77th Street', 'Central', 'Devonshire', 'Foothill', 'Harbor', 'Hollenbeck',
    'Hollywood', 'Mission', 'N Hollywood', 'Newton', 'Northeast', 'Olympic',
    'Pacific', 'Rampart', 'Southeast', 'Southwest', 'Topanga', 'Van Nuys',
    'West LA', 'West Valley', 'Wilshire'
]

# 1. Conteo de crímenes por área
area_counts = df['area_name'].value_counts()

# 2. Asegurarnos que todas las áreas estén (rellenar con 0 si no existen)
area_counts = area_counts.reindex(area_names, fill_value=0)

# 3. Detectar áreas sin crímenes
areas_sin_crimen = area_counts[area_counts == 0].index.tolist()

print("Áreas donde no hubo crímenes:")
print(areas_sin_crimen)

# 4. Filtrar el df para filas con esas áreas (debería estar vacío, o muy pequeño si algo raro pasó)
df_sin_crimenes = df[df['area_name'].isin(areas_sin_crimen)]

# 5. Mostrar las filas
print(df_sin_crimenes)









# Mostrar los valores únicos de la columna 'district'
if 'district' in df.columns:
    print("--- district ---")
    print(sorted(df['district'].dropna().unique()))
    print("\n")
else:
    print("Column 'district' not found in the dataframe.\n")


# Asegurar que 'district' es string para extraer prefijos fácilmente
df['district'] = df['district'].astype(str)

# Extraer primer dígito (o primeros dos dígitos si quieres más precisión)
df['area_code'] = df['district'].str[0].astype(int)

# Opcionalmente, si quieres extraer dos primeros dígitos:
# df['area_code'] = df['district'].str[:2].astype(int)

# Definir los áreas válidas (1 al 21)
valid_areas = list(range(1, 22))

# Marcar si es un área válida
df['area_valid'] = df['area_code'].isin(valid_areas)

# Verificar resultados
print(df['area_valid'].value_counts())

# Ver ejemplos
print(df[['district', 'area_code', 'area_valid']].head())



# Contar cuántos registros NO son válidos
invalid_count = (~df['area_valid']).sum()

print(f"Cantidad de registros con area_valid == False: {invalid_count}")









# Comprobar si un mismo crime_code tiene varias descripciones
crime_mapping = df[['crime_code', 'crime_desc']].drop_duplicates()

# Verificar duplicados de crime_code
duplicates = crime_mapping.duplicated(subset=['crime_code'], keep=False)
crime_mapping[duplicates]





# Crear tabla resumen de códigos de crimen y su descripción
crime_table = df[['crime_code', 'crime_desc']].drop_duplicates().sort_values('crime_code')

# Mostrar la tabla
crime_table.reset_index(drop=True, inplace=True)
crime_table



crime_table.to_csv('crime_code_description.csv', index=False)





import pandas as pd

# Suponemos que tienes un DataFrame llamado 'df' con las columnas 'crime_code' y 'crime_desc'

# Mapeo de crime_codes a categorías UCR
ucr_mapping = {
    # Part I - Violent Crimes
    110: 'HOMICIDE',
    113: 'MANSLAUGHTER',
    121: 'RAPE',
    122: 'ATTEMPTED RAPE',
    815: 'SEXUAL PENETRATION',
    820: 'ORAL COPULATION',
    821: 'SODOMY',
    210: 'ROBBERY',
    220: 'ROBBERY ATTEMPTED',
    230: 'AGGRAVATED ASSAULT',
    231: 'AGGRAVATED ASSAULT',
    235: 'AGGRAVATED ASSAULT',
    236: 'AGGRAVATED ASSAULT',
    250: 'AGGRAVATED ASSAULT',
    251: 'AGGRAVATED ASSAULT',
    761: 'AGGRAVATED ASSAULT',
    926: 'AGGRAVATED ASSAULT',
    435: 'SIMPLE ASSAULT',
    436: 'SIMPLE ASSAULT',
    437: 'SIMPLE ASSAULT',
    622: 'SIMPLE ASSAULT',
    623: 'SIMPLE ASSAULT',
    624: 'SIMPLE ASSAULT',
    625: 'SIMPLE ASSAULT',
    626: 'SIMPLE ASSAULT',
    627: 'SIMPLE ASSAULT',
    647: 'SIMPLE ASSAULT',
    763: 'SIMPLE ASSAULT',
    928: 'SIMPLE ASSAULT',
    930: 'SIMPLE ASSAULT',

    # Part I - Property Crimes
    310: 'BURGLARY',
    320: 'BURGLARY',
    510: 'MOTOR VEHICLE THEFT',
    520: 'MOTOR VEHICLE THEFT',
    433: 'MOTOR VEHICLE THEFT',
    330: 'THEFT FROM VEHICLE',
    331: 'THEFT FROM VEHICLE',
    410: 'THEFT FROM VEHICLE',
    420: 'THEFT FROM VEHICLE',
    421: 'THEFT FROM VEHICLE',
    350: 'PERSONAL THEFT',
    351: 'PERSONAL THEFT',
    352: 'PERSONAL THEFT',
    353: 'PERSONAL THEFT',
    450: 'PERSONAL THEFT',
    451: 'PERSONAL THEFT',
    452: 'PERSONAL THEFT',
    453: 'PERSONAL THEFT',
    341: 'OTHER THEFT',
    343: 'OTHER THEFT',
    345: 'OTHER THEFT',
    440: 'OTHER THEFT',
    441: 'OTHER THEFT',
    442: 'OTHER THEFT',
    443: 'OTHER THEFT',
    444: 'OTHER THEFT',
    445: 'OTHER THEFT',
    470: 'OTHER THEFT',
    471: 'OTHER THEFT',
    472: 'OTHER THEFT',
    473: 'OTHER THEFT',
    474: 'OTHER THEFT',
    475: 'OTHER THEFT',
    480: 'OTHER THEFT',
    485: 'OTHER THEFT',
    487: 'OTHER THEFT',
    491: 'OTHER THEFT',

    # Part II - Other Crimes
    500: 'DRUG OFFENSES',
    501: 'DRUG OFFENSES',
    502: 'DRUG OFFENSES',
    503: 'DRUG OFFENSES',
    504: 'DRUG OFFENSES',
    505: 'DRUG OFFENSES',
    506: 'DRUG OFFENSES',
    600: 'SIMPLE ASSAULT',
    601: 'SIMPLE ASSAULT',
    602: 'SIMPLE ASSAULT',
    603: 'SIMPLE ASSAULT',
    700: 'VANDALISM',
    701: 'VANDALISM',
    702: 'WEAPONS OFFENSE',
    703: 'WEAPONS OFFENSE',
    704: 'WEAPONS OFFENSE',
    705: 'WEAPONS OFFENSE',
    800: 'SEX OFFENSES (NON-RAPE)',
    801: 'SEX OFFENSES (NON-RAPE)',
    802: 'SEX OFFENSES (NON-RAPE)',
    803: 'SEX OFFENSES (NON-RAPE)',
    900: 'OTHER OFFENSES',
    901: 'OTHER OFFENSES',
    902: 'OTHER OFFENSES',
    903: 'OTHER OFFENSES',
    904: 'OTHER OFFENSES',
    905: 'OTHER OFFENSES',
    906: 'OTHER OFFENSES',
    907: 'OTHER OFFENSES'
}

# Crear nueva columna 'crime_ucr' basada en el mapping
df['crime_ucr'] = df['crime_code'].map(ucr_mapping).fillna('UNKNOWN')

# Si quieres ver los resultados
print(df[['crime_code', 'crime_desc', 'crime_ucr']].head())



df.columns





# 1. Primero, corregimos H -> M
df['sex_victim'] = df['sex_victim'].replace('H', 'M')

# 2. Definimos la lista válida final
valores_validos_sexo = ['-', 'F', 'M', 'X']

# 3. Comprobamos de nuevo si queda todo limpio
print("Valores únicos en sex_victim después de la corrección:")
print(df['sex_victim'].unique())

# 4. Opcional: identificar si queda algo inválido
valores_invalidos = df[~df['sex_victim'].isin(valores_validos_sexo)]

print(f"\nCantidad de registros con sex_victim inválido después de corregir: {len(valores_invalidos)}")



# Reemplazar nulos por '-'
df['sex_victim'] = df['sex_victim'].fillna('-')

# Volver a verificar
print("Valores únicos en sex_victim después de rellenar NaN:")
print(df['sex_victim'].unique())


# 1. Conteo de sex_victim
conteo_sexo = df['sex_victim'].value_counts()

# 2. Porcentaje de sex_victim
porcentaje_sexo = df['sex_victim'].value_counts(normalize=True) * 100

# 3. Mostrar resultados
resultado = pd.DataFrame({
    'Cantidad': conteo_sexo,
    'Porcentaje (%)': porcentaje_sexo.round(2)
})

print(resultado)





# 1. Definimos los valores válidos
valores_validos_descent = ['-', 'A', 'B', 'C', 'D', 'F', 'G', 'H', 'I', 'J', 
                           'K', 'L', 'O', 'P', 'S', 'U', 'V', 'W', 'X', 'Z']

# 2. Verificamos los valores únicos en el dataset
print("Valores únicos en descent_victim:")
print(df['descent_victim'].unique())

# 3. Detectamos valores inválidos
valores_invalidos = df[~df['descent_victim'].isin(valores_validos_descent)]

# 4. Mostramos las filas con descent_victim inválido
print("\nFilas con valores inválidos en descent_victim:")
print(valores_invalidos[['id_report', 'descent_victim']])

# 5. Cantidad de registros inválidos
print(f"\nCantidad de registros con descent_victim inválido: {len(valores_invalidos)}")


# Reemplazar NaN por '-'
df['descent_victim'] = df['descent_victim'].fillna('-')


# 1. Definir los valores válidos de razas
valores_validos_descent = ['-', 'A', 'B', 'C', 'D', 'F', 'G', 'H', 'I', 'J', 
                           'K', 'L', 'O', 'P', 'S', 'U', 'V', 'W', 'X', 'Z']

# 2. Rellenar nulos si es necesario
df['descent_victim'] = df['descent_victim'].fillna('-')

# 3. Conteo de víctimas por raza
conteo_raza = df['descent_victim'].value_counts()

# 4. Porcentaje por raza
porcentaje_raza = df['descent_victim'].value_counts(normalize=True) * 100

# 5. Crear el DataFrame resultado
resultado_raza = pd.DataFrame({
    'Cantidad': conteo_raza,
    'Porcentaje (%)': porcentaje_raza.round(2)
})

# 6. Mostrar resultados
print(resultado_raza)





df = pd.read_csv('Crime_Data_from_2020_to_Present.csv') 
unique_status = df['Status'].unique()
print("Valores únicos en la columna 'Status':")
print(unique_status)

non_standard_status = df[df['Status'].isin(['AO', 'JO'])]
result = non_standard_status[['Status', 'Status Desc']].head(5)
print(result)


status_not_null = df['Status'].notna()
total_status = status_not_null.sum()

non_standard_count = df['Status'].isin(['AO', 'JO']).sum()
percentage = (non_standard_count / total_status) * 100

print(f"Cantidad total de valores no estándar ('AO' y 'JO'): {non_standard_count}")
print(f"Porcentaje respecto al total de valores definidos en 'Status': {percentage:.2f}%")



null_count = df['Status'].isna().sum()
total_rows = len(df)
null_percentage = (null_count / total_rows) * 100

print(f"Cantidad de valores nulos en 'Status': {null_count}")
print(f"Porcentaje respecto al total de filas: {null_percentage:.2f}%")


null_count_desc = df['Status Desc'].isna().sum()
total_rows = len(df)
null_percentage_desc = (null_count_desc / total_rows) * 100

print(f"Cantidad de valores nulos en 'Status Desc': {null_count_desc}")
print(f"Porcentaje respecto al total de filas: {null_percentage_desc:.2f}%")



status_null_rows = df[df['Status'].isna()]
print(status_null_rows[['Status Desc']])





df['id_report'].info()


df.iloc[:, :5].head(10)


df.info()





df['date_report']=pd.to_datetime(df['date_report'])


df['date_report'] = df['date_report'].dt.strftime('%d/%m/%Y')


df['date_report']=pd.to_datetime(df['date_report'], format = '%d/%m/%Y')


df['date_report'].head()


df['date_report'].info()

















































































































features_explore_JA = ['id_report','date_report','date_ocurrance','time_ocurrance','area_code','area_name','age_victim','location','cross_street','latitude','longitude']


df[features_explore_JA].info()


df[features_explore_JA].describe()


df_categorical = df[features_explore_JA].select_dtypes(include='object')
df_categorical.describe()


df.loc[df['id_report']<9999999]


df['age_victim'].loc[df['age_victim']<0]


df[features_explore_JA]



